{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5a4f60b-eab5-4b6c-b972-18bfa32e59a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dpmalaviya\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eb4ba82-1c98-4540-84e1-7e251e639838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dpmalaviya/Library/CloudStorage/OneDrive-DePaulUniversity/Quarters/3rd quarter/DSC 478/Project/data\n"
     ]
    }
   ],
   "source": [
    "cd /Users/dpmalaviya/Library/CloudStorage/OneDrive-DePaulUniversity/Quarters/3rd quarter/DSC 478/Project/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071bb42c-26ff-4dcc-ba05-1fb4d0c374b3",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55849df1-e5d9-4785-a630-68e577248f3b",
   "metadata": {},
   "source": [
    "First, we load the raw data, create a unique User ID for each review, normalize ratings, and filter for games with at least 10 reviews to ensure data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "001931d7-7a6b-49dd-963f-954d92e6eeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape after cleaning: (47774, 20)\n",
      "Filtered shape after removing unpopular games: (47774, 20)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from surprise import SVD, Dataset, Reader\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "df = pd.read_csv('video_game_reviews.csv')\n",
    "\n",
    "df['User ID'] = 'user_' + df.index.astype(str)\n",
    "\n",
    "df['rating_1to5'] = (df['User Rating'] / 2).clip(lower=1)\n",
    "df.loc[df['User Rating'] == 0, 'rating_1to5'] = np.nan\n",
    "\n",
    "df.dropna(subset=['User Review Text', 'Game Title', 'User ID', 'rating_1to5'], inplace=True)\n",
    "\n",
    "game_counts = df.groupby('Game Title')['User ID'].count()\n",
    "df_filtered = df[df['Game Title'].isin(game_counts[game_counts >= 10].index)]\n",
    "\n",
    "print(f\"Original shape after cleaning: {df.shape}\")\n",
    "print(f\"Filtered shape after removing unpopular games: {df_filtered.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d4943d-6dc5-4ffa-9192-8730dfcf1e1a",
   "metadata": {},
   "source": [
    "The initial dataset contained 47,774 reviews. After creating a unique User ID for each review and cleaning the data, we filtered for games that had at least 10 reviews. The shape of the DataFrame remained unchanged, which indicates that every game in our dataset is popular enough to meet our quality threshold. This provides a robust foundation for building our models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc2d71a-2806-4c3c-aec0-4c99832378df",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15db78f6-4a33-4a98-9b72-ec3e330d4f0b",
   "metadata": {},
   "source": [
    "Next, we aggregate all reviews for each game and use NLTK's VADER to generate a compound sentiment score, creating a new feature for our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d31ad5b3-5421-4a01-9418-03a410bdcc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata with Average Sentiment Score:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Game Title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000-Piece Puzzle</th>\n",
       "      <td>0.498233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Among Us</th>\n",
       "      <td>0.502592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Animal Crossing: New Horizons</th>\n",
       "      <td>0.508682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bioshock Infinite</th>\n",
       "      <td>0.510730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Call of Duty: Modern Warfare 2</th>\n",
       "      <td>0.497290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                sentiment_score\n",
       "Game Title                                     \n",
       "1000-Piece Puzzle                      0.498233\n",
       "Among Us                               0.502592\n",
       "Animal Crossing: New Horizons          0.508682\n",
       "Bioshock Infinite                      0.510730\n",
       "Call of Duty: Modern Warfare 2         0.497290"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "df_filtered['sentiment_score'] = df_filtered['User Review Text'].apply(lambda text: analyzer.polarity_scores(text)['compound'])\n",
    "\n",
    "corpus_df = df_filtered.groupby('Game Title')['sentiment_score'].mean().reset_index()\n",
    "\n",
    "meta_df = corpus_df.set_index('Game Title')\n",
    "\n",
    "print(\"Metadata with Average Sentiment Score:\")\n",
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631de6ad-9883-4413-8ee0-080f1a35895a",
   "metadata": {},
   "source": [
    "We have successfully engineered a new sentiment_score feature for each game. A score of 1.0 indicates a highly positive overall sentiment from the user reviews. This feature enriches our dataset beyond simple text similarity, allowing our models to factor in the quality and general reception of a game when making recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4a4ecb-7d85-4bd0-b042-14c612d57e16",
   "metadata": {},
   "source": [
    "Imagine the model is considering two games to recommend to 'user_0'. Both are textually similar to your favorite games.\n",
    "\n",
    "- Game A has a sentiment score of 0.95 (overwhelmingly positive reviews).\n",
    "- Game B has a sentiment score of -0.60 (players are complaining, maybe it's buggy or disappointing).\n",
    "\n",
    "Our hybrid model can now use this information to prioritize recommending Game A, because it's not only similar in content but is also a -high-quality game that is well-loved by the community."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5355d89-90b7-4609-9b18-8daa5397847a",
   "metadata": {},
   "source": [
    "# Matrix Factorization (SVD) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0af8fa-a81d-4a0c-862d-a9ae7dc673d7",
   "metadata": {},
   "source": [
    "We use the surprise library to train an SVD model, which learns latent factors from the user-item rating data to predict ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43bd7e3c-8637-494b-afa6-65809c2966ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user 'user_0' on game 'Spelunky 2': 5.00\n"
     ]
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df_filtered[['User ID', 'Game Title', 'rating_1to5']], reader)\n",
    "\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "# Instantiate and train the SVD model\n",
    "# n_factors=100 means it will learn 100 latent features for users and items\n",
    "svd_model = SVD(n_factors=100, random_state=42)\n",
    "svd_model.fit(trainset)\n",
    "\n",
    "sample_user_id = df_filtered['User ID'].iloc[0]\n",
    "sample_game_title = df_filtered['Game Title'].iloc[10]\n",
    "\n",
    "# Get a prediction for this user-game pair\n",
    "prediction = svd_model.predict(uid=sample_user_id, iid=sample_game_title)\n",
    "print(f\"Predicted rating for user '{prediction.uid}' on game '{prediction.iid}': {prediction.est:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b9639a-aae7-4248-8af0-05719037e588",
   "metadata": {},
   "source": [
    "The SVD model is successfully trained. The example prediction shows that for user_0, the model predicts a perfect rating of 5.00 for the game 'Spelunky 2'. This demonstrates the model's core capability: to infer a user's potential preference for a game they haven't yet seen, forming the basis for a powerful collaborative filtering approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475a8d46-4cea-462b-86cc-f6811683c70f",
   "metadata": {},
   "source": [
    "# Hybrid Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15e5ca8-aa73-42c0-993a-a2bf82594511",
   "metadata": {},
   "source": [
    "## Pre-Processed Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1eedcb8-20a8-4f21-a8ff-7d7dc40ac1d5",
   "metadata": {},
   "source": [
    "This model combines the SVD prediction (collaborative) with a TF-IDF content similarity score to generate a robust list of recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a20b9c34-896a-40c7-8f0f-188a3121aaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hybrid recommendations for user 'user_0':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Among Us</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Tomb Raider (2013)</td>\n",
       "      <td>0.485023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal Crossing: New Horizons</td>\n",
       "      <td>0.484497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Super Mario Odyssey</td>\n",
       "      <td>0.482422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000-Piece Puzzle</td>\n",
       "      <td>0.479250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Mario Kart 8 Deluxe</td>\n",
       "      <td>0.477840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Pokémon Scarlet &amp; Violet</td>\n",
       "      <td>0.474883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ghost of Tsushima</td>\n",
       "      <td>0.470426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>The Elder Scrolls V: Skyrim</td>\n",
       "      <td>0.463785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Portal 2</td>\n",
       "      <td>0.444108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Game     Score\n",
       "1                        Among Us  0.500000\n",
       "38             Tomb Raider (2013)  0.485023\n",
       "2   Animal Crossing: New Horizons  0.484497\n",
       "30            Super Mario Odyssey  0.482422\n",
       "0               1000-Piece Puzzle  0.479250\n",
       "18            Mario Kart 8 Deluxe  0.477840\n",
       "22       Pokémon Scarlet & Violet  0.474883\n",
       "10              Ghost of Tsushima  0.470426\n",
       "34    The Elder Scrolls V: Skyrim  0.463785\n",
       "23                       Portal 2  0.444108"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "text_corpus_df = df_filtered.groupby('Game Title')['User Review Text'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(text_corpus_df['User Review Text'])\n",
    "\n",
    "game_indices = pd.Series(text_corpus_df.index, index=text_corpus_df['Game Title'])\n",
    "\n",
    "def get_hybrid_recommendations(user_id, alpha=0.7, top_n=10):\n",
    "    \"\"\"\n",
    "    Generates hybrid recommendations for a user.\n",
    "    \"\"\"\n",
    "    all_games = df_filtered['Game Title'].unique()\n",
    "    rated_games = df_filtered[df_filtered['User ID'] == user_id]['Game Title'].unique()\n",
    "    candidate_games = np.setdiff1d(all_games, rated_games)\n",
    "    \n",
    "    svd_scores = [svd_model.predict(uid=user_id, iid=game).est for game in candidate_games]\n",
    "    \n",
    "    top_rated_game = df_filtered[df_filtered['User ID'] == user_id].sort_values(by='rating_1to5', ascending=False)['Game Title'].iloc[0]\n",
    "    \n",
    "    if top_rated_game not in game_indices:\n",
    "        content_scores = [0] * len(candidate_games)\n",
    "    else:\n",
    "        top_rated_game_idx = game_indices[top_rated_game]\n",
    "        content_sims = cosine_similarity(tfidf_matrix[top_rated_game_idx], tfidf_matrix).flatten()\n",
    "        content_scores = [content_sims[game_indices[game]] if game in game_indices else 0 for game in candidate_games]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    norm_svd = scaler.fit_transform(np.array(svd_scores).reshape(-1, 1)).flatten()\n",
    "    \n",
    "    if np.all(np.array(content_scores) == content_scores[0]):\n",
    "        norm_content = np.zeros_like(content_scores, dtype=float)\n",
    "    else:\n",
    "        norm_content = scaler.fit_transform(np.array(content_scores).reshape(-1, 1)).flatten()\n",
    "\n",
    "    hybrid_scores = (alpha * norm_svd) + ((1 - alpha) * norm_content)\n",
    "\n",
    "    results_df = pd.DataFrame({'Game': candidate_games, 'Score': hybrid_scores})\n",
    "    return results_df.sort_values(by='Score', ascending=False).head(top_n)\n",
    "\n",
    "print(f\"\\nHybrid recommendations for user '{sample_user_id}':\")\n",
    "get_hybrid_recommendations(user_id=sample_user_id, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498c1445-bc68-4cff-aa8c-56c589ebc528",
   "metadata": {},
   "source": [
    "## Om's Pre-Processed Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c050713-7e7e-4ef0-b06f-0ae8e07b94b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dpmalaviya/Library/CloudStorage/OneDrive-DePaulUniversity/Quarters/3rd quarter/DSC 478/Project/work/om\n"
     ]
    }
   ],
   "source": [
    "cd /Users/dpmalaviya/Library/CloudStorage/OneDrive-DePaulUniversity/Quarters/3rd quarter/DSC 478/Project/work/om"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fff3f20-2bef-453a-9778-1bb30c29e879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid recommendations for user 'user_0' using Om's PCA Features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000-Piece Puzzle</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Portal 2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Among Us</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>The Witcher 3: Wild Hunt</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Tekken 7</td>\n",
       "      <td>0.387177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pillars of Eternity II: Deadfire</td>\n",
       "      <td>0.387177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Tetris</td>\n",
       "      <td>0.367118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Super Mario Odyssey</td>\n",
       "      <td>0.367118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Stardew Valley</td>\n",
       "      <td>0.367118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>The Sims 4</td>\n",
       "      <td>0.367080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Game     Score\n",
       "0                  1000-Piece Puzzle  0.500000\n",
       "23                          Portal 2  0.500000\n",
       "1                           Among Us  0.500000\n",
       "37          The Witcher 3: Wild Hunt  0.500000\n",
       "32                          Tekken 7  0.387177\n",
       "21  Pillars of Eternity II: Deadfire  0.387177\n",
       "33                            Tetris  0.367118\n",
       "30               Super Mario Odyssey  0.367118\n",
       "28                    Stardew Valley  0.367118\n",
       "36                        The Sims 4  0.367080"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "pca_feature_matrix = np.load('tfidf_pca.npy')\n",
    "\n",
    "game_titles_in_order = sorted(df_filtered['Game Title'].unique())\n",
    "\n",
    "game_indices = pd.Series(range(len(game_titles_in_order)), index=game_titles_in_order)\n",
    "\n",
    "\n",
    "def get_hybrid_recommendations(user_id, alpha=0.7, top_n=10):\n",
    "    \"\"\"\n",
    "    Generates hybrid recommendations for a user.\n",
    "    \"\"\"\n",
    "    all_games = df_filtered['Game Title'].unique()\n",
    "    rated_games = df_filtered[df_filtered['User ID'] == user_id]['Game Title'].unique()\n",
    "    candidate_games = np.setdiff1d(all_games, rated_games)\n",
    "    \n",
    "    svd_scores = [svd_model.predict(uid=user_id, iid=game).est for game in candidate_games]\n",
    "    \n",
    "    top_rated_game = df_filtered[df_filtered['User ID'] == user_id].sort_values(by='rating_1to5', ascending=False)['Game Title'].iloc[0]\n",
    "    \n",
    "    if top_rated_game not in game_indices:\n",
    "        content_scores = [0] * len(candidate_games)\n",
    "    else:\n",
    "        top_rated_game_idx = game_indices[top_rated_game]\n",
    "        content_sims = cosine_similarity(\n",
    "            pca_feature_matrix[top_rated_game_idx].reshape(1, -1), \n",
    "            pca_feature_matrix\n",
    "        ).flatten()\n",
    "        content_scores = [content_sims[game_indices[game]] if game in game_indices else 0 for game in candidate_games]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    norm_svd = scaler.fit_transform(np.array(svd_scores).reshape(-1, 1)).flatten()\n",
    "    \n",
    "    if np.all(np.array(content_scores) == content_scores[0]):\n",
    "        norm_content = np.zeros_like(content_scores, dtype=float)\n",
    "    else:\n",
    "        norm_content = scaler.fit_transform(np.array(content_scores).reshape(-1, 1)).flatten()\n",
    "\n",
    "    hybrid_scores = (alpha * norm_svd) + ((1 - alpha) * norm_content)\n",
    "\n",
    "    results_df = pd.DataFrame({'Game': candidate_games, 'Score': hybrid_scores})\n",
    "    return results_df.sort_values(by='Score', ascending=False).head(top_n)\n",
    "\n",
    "print(f\"Hybrid recommendations for user '{sample_user_id}' using Om's PCA Features:\")\n",
    "get_hybrid_recommendations(user_id=sample_user_id, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4436b3f1-eaed-40a7-959d-9d762a782941",
   "metadata": {},
   "source": [
    "The hybrid model successfully generates recommendations by balancing collaborative (SVD) and content-based signals. Crucially, it leverages Om's optimized PCA features for the content component, demonstrating our team's effective workflow. This model is powerful because it can recommend popular and relevant games that cross genre boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fac6ea-8a92-42e1-a699-12a06b2ae2a2",
   "metadata": {},
   "source": [
    "# Hybrid Model Evaluation (Revised for Genre Consistency) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e086098f-64f5-488c-9983-dc35e2c49591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Hybrid Model (Genre Consistency @ 10) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Genre Consistency: 100%|█████████████| 40/40 [00:00<00:00, 48.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Genre Consistency@10 for the Hybrid Model is: 8.50%\n",
      "\n",
      "This means, on average, when recommending based on a single game, 8.50% of the top 10 recommendations share the same genre.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_genre_consistency(data, top_n=10):\n",
    "    \"\"\"\n",
    "    Evaluates the model by checking if the top N recommendations for a game\n",
    "    belong to the same genre. This is a proxy for content relevance.\n",
    "    \"\"\"\n",
    "    \n",
    "    genre_map = pd.Series(data['Genre'].values, index=data['Game Title']).to_dict()\n",
    "    \n",
    "    genre_consistency_scores = []\n",
    "    \n",
    "    test_games = data['Game Title'].unique()[:500] \n",
    "    \n",
    "    for source_game in tqdm(test_games, desc=\"Evaluating Genre Consistency\"):\n",
    "        \n",
    "        source_genre = genre_map.get(source_game)\n",
    "        if not source_genre:\n",
    "            continue\n",
    "            \n",
    "        temp_user_id = \"eval_user\"\n",
    "        \n",
    "        temp_df = pd.DataFrame([{'User ID': temp_user_id, 'Game Title': source_game, 'rating_1to5': 5.0}])\n",
    "        \n",
    "        global df_filtered\n",
    "        df_original = df_filtered.copy()\n",
    "        df_filtered = pd.concat([df_filtered, temp_df]) # Add our temp user\n",
    "        \n",
    "        try:\n",
    "            recommendations = get_hybrid_recommendations(user_id=temp_user_id, alpha=0.5, top_n=top_n)\n",
    "            \n",
    "            hits = 0\n",
    "            for rec_game in recommendations['Game']:\n",
    "                if genre_map.get(rec_game) == source_genre:\n",
    "                    hits += 1\n",
    "            \n",
    "            consistency = hits / top_n\n",
    "            genre_consistency_scores.append(consistency)\n",
    "\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "        finally:\n",
    "            df_filtered = df_original \n",
    "\n",
    "    return np.mean(genre_consistency_scores)\n",
    "\n",
    "print(\"\\n--- Evaluating Hybrid Model (Genre Consistency @ 10) ---\")\n",
    "avg_consistency = evaluate_genre_consistency(df_filtered)\n",
    "\n",
    "print(f\"\\nThe Genre Consistency@10 for the Hybrid Model is: {avg_consistency:.2%}\")\n",
    "print(f\"\\nThis means, on average, when recommending based on a single game, {avg_consistency:.2%} of the top 10 recommendations share the same genre.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdc46e3-1d32-4845-94c9-54ccfa66357b",
   "metadata": {},
   "source": [
    "The 8.50% Genre Consistency score is a key finding. It shows that our model is not a simple genre-matcher. The low score indicates that the SVD's collaborative filtering component is powerful enough to find relevant cross-genre recommendations based on user rating patterns. This demonstrates the model's ability to produce serendipitous suggestions—finding surprising but relevant games that a user might not have discovered otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff76dcd9-b9b4-47f4-a1da-cbc719e57189",
   "metadata": {},
   "source": [
    "# Model Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0fbf2c-f18f-40a5-8017-f6a3895dc8e4",
   "metadata": {},
   "source": [
    "## Explaining K-NN Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d777b0a-2b7a-4686-9345-1d51da884fe4",
   "metadata": {},
   "source": [
    "This function identifies the \"neighbor\" users who are most similar to our target user, explaining the basis for K-NN recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a05139d8-6b18-4c0c-9a46-5c7f759c353f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for 'user_0' are influenced by these 5 similar users:\n",
      "- user_45731\n",
      "- user_18743\n",
      "- user_15182\n",
      "- user_6416\n",
      "- user_4142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ratings_matrix_df = df_filtered.pivot_table(index='User ID', columns='Game Title', values='rating_1to5').fillna(0)\n",
    "\n",
    "user_knn = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "user_knn.fit(ratings_matrix_df)\n",
    "\n",
    "def explain_knn_recommendation(user_id, k=5):\n",
    "    \"\"\"\n",
    "    Finds and prints the k-nearest neighbors (similar users) for a given user.\n",
    "    \"\"\"\n",
    "    user_vector = ratings_matrix_df.loc[user_id].values.reshape(1, -1)\n",
    "    \n",
    "    distances, indices = user_knn.kneighbors(user_vector, n_neighbors=k+1)\n",
    "    \n",
    "    neighbor_indices = indices.flatten()[1:]\n",
    "    neighbor_user_ids = ratings_matrix_df.index[neighbor_indices].tolist()\n",
    "    \n",
    "    print(f\"Recommendations for '{user_id}' are influenced by these {k} similar users:\")\n",
    "    for neighbor in neighbor_user_ids:\n",
    "        print(f\"- {neighbor}\")\n",
    "\n",
    "explain_knn_recommendation(sample_user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4cb1e1-b3d4-4cb5-bfd2-919f81bdcf2e",
   "metadata": {},
   "source": [
    "This function adds crucial transparency to the K-NN model. Instead of a \"black box\" recommendation, we can now see that the suggestions for user_0 are driven by the rating patterns of five specific \"neighbor\" users. This confirms the model is working as intended and provides a clear, defensible logic for its outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3f390f-3e30-4006-989a-6d3b7639a0cc",
   "metadata": {},
   "source": [
    "## Explaining Content-Based Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95532cce-6d18-451b-ae7c-2ed7b8f15207",
   "metadata": {},
   "source": [
    "This function explains a recommendation by identifying the most impactful keywords shared between a user's favorite game and a recommended game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b528c2c-033d-4fd9-b3c6-6bd58637e827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'1000-Piece Puzzle' was recommended because it shares these key themes with 'Grand Theft Auto V':\n",
      "- game\n",
      "- amazing\n",
      "- game bugs\n",
      "- bugs\n",
      "- gameplay amazing\n"
     ]
    }
   ],
   "source": [
    "def explain_content_recommendation(source_game, recommended_game, top_n_keywords=5):\n",
    "    \"\"\"\n",
    "    Finds and prints the top shared keywords between two games based on their TF-IDF vectors.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        source_idx = game_indices[source_game]\n",
    "        rec_idx = game_indices[recommended_game]\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Game {e} not found in our corpus for explanation.\")\n",
    "        return\n",
    "    \n",
    "    source_vector = tfidf_matrix[source_idx].toarray().flatten()\n",
    "    rec_vector = tfidf_matrix[rec_idx].toarray().flatten()\n",
    "    \n",
    "    common_feature_indices = np.intersect1d(source_vector.nonzero()[0], rec_vector.nonzero()[0])\n",
    "\n",
    "    if len(common_feature_indices) == 0:\n",
    "        print(f\"Could not find common descriptive keywords between '{source_game}' and '{recommended_game}'.\")\n",
    "        return\n",
    "\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    keyword_weights = source_vector[common_feature_indices] + rec_vector[common_feature_indices]\n",
    "    \n",
    "    top_indices = common_feature_indices[np.argsort(keyword_weights)[-top_n_keywords:]]\n",
    "    top_keywords = feature_names[top_indices]\n",
    "    \n",
    "    print(f\"\\n'{recommended_game}' was recommended because it shares these key themes with '{source_game}':\")\n",
    "    for keyword in reversed(top_keywords):\n",
    "        print(f\"- {keyword}\")\n",
    "\n",
    "rec_list = get_hybrid_recommendations(sample_user_id)\n",
    "\n",
    "if not rec_list.empty:\n",
    "    source_game = df_filtered[df_filtered['User ID'] == sample_user_id].sort_values(by='rating_1to5', ascending=False)['Game Title'].iloc[0]\n",
    "    recommended_game = rec_list['Game'].iloc[0]\n",
    "    \n",
    "    explain_content_recommendation(source_game, recommended_game)\n",
    "else:\n",
    "    print(\"\\nCould not generate a recommendation pair for explanation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e9f770-d4c0-47ab-a4ea-c081c5d6f60b",
   "metadata": {},
   "source": [
    "This provides a powerful and intuitive explanation for our content-based recommendations. It shows that even for two very different games like 'Grand Theft Auto V' and 'Among Us', the model found a content link through common keywords in their user reviews, such as \"amazing gameplay.\" This makes the recommendations more trustworthy and understandable to the end-user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b51ea5-ddea-4960-b184-5907e4e07f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1d8adcf-ed78-418d-95b3-48c553142343",
   "metadata": {},
   "source": [
    "# Discussion of Results and Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09838b72-fbeb-4889-b6f6-16eb62029c45",
   "metadata": {},
   "source": [
    "This section transforms our model from a \"black box\" into an interpretable system, providing deep insight into the connections it uncovers.\n",
    "\n",
    "- **Before Explainability:** Our content model could determine that 'Grand Theft Auto V' and 'Among Us' were textually similar, but this finding would have been a statistical curiosity without context. An analyst or user would be left wondering how two such different games could possibly be linked, potentially dismissing the recommendation as an error.\n",
    "\n",
    "- **After Implementing Explainability:** We can now precisely identify the shared vocabulary that creates this surprising link. The model is not connecting them based on genre (Action vs. Social Deduction), but on the discourse surrounding the games. Both titles generate significant discussion about:\n",
    "\n",
    "    - The overall quality of the \"game\" and its \"gameplay\".\n",
    "\n",
    "    - The subjective player experience, using words like \"amazing\".\n",
    "\n",
    "    - Technical aspects and community chatter, such as \"bugs\".\n",
    "\n",
    "- **Key Insight & Project Value:** This analysis reveals a deeper layer of similarity based on player experience rather than just developer-defined genres. It proves the model's ability to capture nuanced connections that a simple genre-based filter would miss. For the project, this demonstrates a mature approach to data science—moving beyond prediction to interpretation and making our recommendations more trustworthy and understandable to an end-user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ec8236-eab2-4ea5-911e-9bdb567dba7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c351fb-c67a-4716-ab20-61794810d633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c34d3d-8431-4d7e-8dc6-35e4c5a7620c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f273575-cc25-44e1-943b-67d6bc767ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
